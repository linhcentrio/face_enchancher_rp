#!/usr/bin/env python3
"""
RunPod Serverless Handler for Face Enhancement using GFPGAN
T√°ch ri√™ng t·ª´ LatentSync service ƒë·ªÉ chuy√™n bi·ªát h√≥a vi·ªác enhance khu√¥n m·∫∑t
"""

import runpod
import os
import tempfile
import uuid
import requests
import time
import cv2
import numpy as np
import torch
import sys
from pathlib import Path
from minio import Minio
from urllib.parse import quote
from tqdm import tqdm
import onnxruntime
import logging
import gc
import subprocess
from datetime import datetime

# Add path for local modules
sys.path.append('/app')

# Import required modules
try:
    from utils.retinaface import RetinaFace
    from utils.face_alignment import get_cropped_head_256
    from enhancers.GFPGAN.GFPGAN import GFPGAN
    from faceID.faceID import FaceRecognition
except ImportError as e:
    logging.error(f"Import error: {e}")
    sys.exit(1)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# MinIO Configuration
MINIO_ENDPOINT = "media.aiclip.ai"
MINIO_ACCESS_KEY = "VtZ6MUPfyTOH3qSiohA2"
MINIO_SECRET_KEY = "8boVPVIynLEKcgXirrcePxvjSk7gReIDD9pwto3t"
MINIO_BUCKET = "video"
MINIO_SECURE = False

# Initialize MinIO client
minio_client = Minio(
    MINIO_ENDPOINT,
    access_key=MINIO_ACCESS_KEY,
    secret_key=MINIO_SECRET_KEY,
    secure=MINIO_SECURE
)

# Global model instances
detector = None
enhancer = None
recognition = None

# Model paths
MODEL_PATHS = {
    "face_detector": "/app/models/face_detection/scrfd_2.5g_bnkps.onnx",
    "face_enhancer": "/app/models/face_enhancement/GFPGANv1.4.onnx",
    "face_recognition": "/app/models/face_detection/recognition.onnx"
}

def create_optimized_session_options():
    """Create optimized ONNX Runtime session options for GPU"""
    session_options = onnxruntime.SessionOptions()
    
    # Optimize for GPU if available
    if 'CUDAExecutionProvider' in onnxruntime.get_available_providers():
        # GPU optimizations
        session_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL
        session_options.execution_mode = onnxruntime.ExecutionMode.ORT_SEQUENTIAL  # Better for GPU
        session_options.enable_cpu_mem_arena = False
        session_options.enable_mem_pattern = False
        session_options.add_session_config_entry('session.disable_prepacking', '1')  # Better GPU memory
        session_options.add_session_config_entry('session.use_env_allocators', '1')
        logger.info("üöÄ Configured session options for GPU execution")
    else:
        # CPU optimizations
        session_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL
        session_options.execution_mode = onnxruntime.ExecutionMode.ORT_PARALLEL
        session_options.enable_cpu_mem_arena = True
        session_options.enable_mem_pattern = True
        session_options.intra_op_num_threads = 0  # Use all available CPU cores
        session_options.inter_op_num_threads = 0
        logger.info("üîÑ Configured session options for CPU execution")
    
    return session_options

def get_optimized_providers():
    """Get optimized ONNX Runtime providers with comprehensive GPU checking"""
    available_providers = onnxruntime.get_available_providers()
    logger.info(f"üîç Available ONNX providers: {available_providers}")
    
    # Check if CUDA is available in both PyTorch and ONNX Runtime
    torch_cuda = torch.cuda.is_available()
    onnx_cuda = 'CUDAExecutionProvider' in available_providers
    
    logger.info(f"üéÆ PyTorch CUDA available: {torch_cuda}")
    logger.info(f"üîß ONNX CUDA provider available: {onnx_cuda}")
    
    if torch_cuda and onnx_cuda:
        # More conservative CUDA settings to avoid fallback
        cuda_provider_options = {
            'device_id': 0,
            'arena_extend_strategy': 'kSameAsRequested',  # More conservative
            'gpu_mem_limit': 6 * 1024 * 1024 * 1024,     # 6GB limit (more conservative)
            'cudnn_conv_algo_search': 'HEURISTIC',        # Faster than EXHAUSTIVE
            'do_copy_in_default_stream': True,
            'enable_cuda_graph': False,                   # Disable for stability
        }
        providers = [
            ('CUDAExecutionProvider', cuda_provider_options),
            'CPUExecutionProvider'
        ]
        logger.info("üöÄ Using optimized CUDA providers")
        
        # Verify GPU info
        if torch_cuda:
            logger.info(f"üéÆ GPU: {torch.cuda.get_device_name()}")
            logger.info(f"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB")
            logger.info(f"üîã GPU Memory Free: {torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated():.0f} bytes")
    else:
        providers = ['CPUExecutionProvider']
        if not torch_cuda:
            logger.warning("‚ö†Ô∏è PyTorch CUDA not available")
        if not onnx_cuda:
            logger.warning("‚ö†Ô∏è ONNX CUDA provider not available. Install onnxruntime-gpu")
        logger.info("üîÑ Falling back to CPU execution")
    
    return providers

def validate_gpu_usage(enhancer):
    """Validate that GPU is actually being used by running a test inference"""
    try:
        if torch.cuda.is_available() and 'CUDAExecutionProvider' in onnxruntime.get_available_providers():
            logger.info("üß™ Testing GPU inference...")
            
            # Create a small test image
            test_img = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
            
            # Clear GPU memory and measure before
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                mem_before = torch.cuda.memory_allocated()
            
            # Run test inference
            start_time = time.time()
            enhanced = enhancer.enhance(test_img)
            inference_time = time.time() - start_time
            
            # Check GPU memory usage after
            if torch.cuda.is_available():
                mem_after = torch.cuda.memory_allocated()
                mem_used = (mem_after - mem_before) / 1024 / 1024  # MB
                
                if mem_used > 0:
                    logger.info(f"‚úÖ GPU inference confirmed! Time: {inference_time:.3f}s, GPU Memory used: {mem_used:.1f}MB")
                else:
                    logger.warning(f"‚ö†Ô∏è GPU memory not increased. Possible CPU fallback. Time: {inference_time:.3f}s")
            else:
                logger.info(f"üîÑ CPU inference completed in {inference_time:.3f}s")
                
            # Verify output shape
            if enhanced.shape == test_img.shape:
                logger.info(f"‚úÖ Test inference successful - Output shape matches input: {enhanced.shape}")
            else:
                logger.error(f"‚ùå Test inference failed - Shape mismatch: {enhanced.shape} vs {test_img.shape}")
                
        else:
            logger.info("üîÑ Skipping GPU validation - CUDA not available")
            
    except Exception as e:
        logger.error(f"‚ùå GPU validation failed: {e}")

def initialize_models():
    """Initialize face enhancement models with optimized ONNX Runtime settings"""
    global detector, enhancer, recognition
    
    try:
        # Create optimized session options
        session_options = create_optimized_session_options()
        providers = get_optimized_providers()
        
        # Initialize face detector v·ªõi optimized settings
        detector_path = MODEL_PATHS["face_detector"]
        if not os.path.exists(detector_path):
            raise FileNotFoundError(f"Face detector model not found: {detector_path}")
            
        detector = RetinaFace(
            detector_path,
            provider=providers,
            session_options=session_options
        )
        logger.info("‚úÖ Face detector initialized with optimized settings")
        
        # Initialize face recognition v·ªõi optimized settings
        recognition_path = MODEL_PATHS["face_recognition"]
        if not os.path.exists(recognition_path):
            raise FileNotFoundError(f"Face recognition model not found: {recognition_path}")
            
        # Create optimized recognition session
        recognition_session = onnxruntime.InferenceSession(
            recognition_path,
            sess_options=session_options,
            providers=providers
        )
        recognition = FaceRecognition(session=recognition_session)
        logger.info("‚úÖ Face recognition initialized with optimized settings")
        
        # Initialize face enhancer v·ªõi optimized settings
        enhancer_path = MODEL_PATHS["face_enhancer"]
        if not os.path.exists(enhancer_path):
            raise FileNotFoundError(f"Face enhancer model not found: {enhancer_path}")
        
        # Determine device for GFPGAN
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        logger.info(f"Running on {device}")
        
        enhancer = GFPGAN(
            model_path=enhancer_path, 
            device=device,
            session_options=session_options,
            providers=providers
        )
        logger.info(f"‚úÖ Face enhancer initialized on {device} with optimized settings")
        
        # Validate that GPU is actually being used
        validate_gpu_usage(enhancer)
        
        # Log providers info
        logger.info(f"üîß Available ONNX providers: {onnxruntime.get_available_providers()}")
        if torch.cuda.is_available():
            logger.info(f"üéÆ GPU: {torch.cuda.get_device_name()}")
            logger.info(f"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB")

    except Exception as e:
        logger.error(f"‚ùå Model initialization failed: {e}")
        raise e

def download_file(url: str, local_path: str) -> bool:
    """Download file from URL with progress tracking"""
    try:
        logger.info(f"üì• Downloading {url}")
        response = requests.get(url, stream=True, timeout=300)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        downloaded = 0
        
        with open(local_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
        
        logger.info(f"‚úÖ Downloaded: {local_path} ({downloaded/1024/1024:.1f} MB)")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Download failed: {e}")
        return False

def upload_to_minio(local_path: str, object_name: str) -> str:
    """Upload file to MinIO with enhanced error handling"""
    try:
        if not os.path.exists(local_path):
            raise FileNotFoundError(f"Local file not found: {local_path}")
        
        minio_client.fput_object(MINIO_BUCKET, object_name, local_path)
        file_url = f"https://{MINIO_ENDPOINT}/{MINIO_BUCKET}/{quote(object_name)}"
        logger.info(f"‚úÖ Uploaded successfully: {file_url}")
        return file_url
        
    except Exception as e:
        logger.error(f"‚ùå Upload failed: {e}")
        raise e

def process_batch(frame_buffer, enhancer, face_mask, out, frame_width, frame_height):
    """Process batch of frames with face enhancement"""
    if not frame_buffer:
        return
    
    # Validate batch size to prevent memory issues
    if len(frame_buffer) > 10:
        logger.warning(f"‚ö†Ô∏è Large batch size detected: {len(frame_buffer)}. Processing in smaller chunks.")
        # Process in smaller chunks
        chunk_size = 5
        for i in range(0, len(frame_buffer), chunk_size):
            chunk = frame_buffer[i:i+chunk_size]
            process_batch(chunk, enhancer, face_mask, out, frame_width, frame_height)
        return
    
    frames, aligned_faces, mats = zip(*frame_buffer)
    enhanced_faces = enhancer.enhance_batch(aligned_faces)
    
    for frame, aligned_face, mat, enhanced_face in zip(frames, aligned_faces, mats, enhanced_faces):
        enhanced_face_resized = cv2.resize(enhanced_face, (aligned_face.shape[1], aligned_face.shape[0]))
        face_mask_resized = cv2.resize(face_mask, (enhanced_face_resized.shape[1], enhanced_face_resized.shape[0]))
        blended_face = (face_mask_resized * enhanced_face_resized + (1 - face_mask_resized) * aligned_face).astype(np.uint8)
        
        mat_rev = cv2.invertAffineTransform(mat)
        dealigned_face = cv2.warpAffine(blended_face, mat_rev, (frame_width, frame_height))
        mask = cv2.warpAffine(face_mask_resized, mat_rev, (frame_width, frame_height))
        final_frame = (mask * dealigned_face + (1 - mask) * frame).astype(np.uint8)
        
        out.write(final_frame)

def enhance_video_with_gfpgan(input_video_path: str, output_path: str = None) -> tuple[bool, dict]:
    """Apply face enhancement to video using GFPGAN"""
    global detector, enhancer
    
    stats = {
        "total_frames": 0,
        "frames_with_faces": 0,
        "frames_without_faces": 0,
        "faces_enhanced": 0,
        "enhancement_applied": False
    }
    
    try:
        logger.info(f"‚ú® Starting face enhancement: {input_video_path}")
        
        video_stream = cv2.VideoCapture(input_video_path)
        if not video_stream.isOpened():
            raise ValueError(f"Failed to open video file: {input_video_path}")
        
        fps = video_stream.get(cv2.CAP_PROP_FPS)
        frame_width = int(video_stream.get(cv2.CAP_PROP_FRAME_WIDTH))
        frame_height = int(video_stream.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(video_stream.get(cv2.CAP_PROP_FRAME_COUNT))
        
        stats["total_frames"] = total_frames
        
        if output_path is None:
            output_path = os.path.splitext(input_video_path)[0] + '_enhanced_gfpgan.mp4'
        
        temp_video_path = output_path.replace('.mp4', '_temp.mp4')
        out = cv2.VideoWriter(temp_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))
        
        # Create face mask for blending
        face_mask = np.zeros((256, 256), dtype=np.uint8)
        face_mask = cv2.rectangle(face_mask, (66, 69), (190, 240), (255, 255, 255), -1)
        face_mask = cv2.GaussianBlur(face_mask.astype(np.uint8), (19, 19), cv2.BORDER_DEFAULT)
        face_mask = cv2.cvtColor(face_mask, cv2.COLOR_GRAY2RGB)
        face_mask = face_mask / 255
        
        batch_size = 2  # Reduced batch size to prevent memory issues
        frame_buffer = []
        
        logger.info(f"Processing {total_frames} frames with face enhancement...")
        
        detection_times = []
        enhancement_times = []
        
        for frame_idx in tqdm(range(total_frames), desc="Enhancing faces"):
            ret, frame = video_stream.read()
            if not ret:
                break
            
            # Try to detect faces v·ªõi timing
            face_detection_start = time.time()
            try:
                bboxes, kpss = detector.detect(frame, input_size=(320, 320), det_thresh=0.3)
                detection_times.append(time.time() - face_detection_start)
            except Exception as e:
                logger.debug(f"Face detection failed for frame {frame_idx}: {e}")
                bboxes, kpss = [], []
                detection_times.append(time.time() - face_detection_start)
            
            if len(kpss) == 0:
                # No face ‚Üí Keep original frame
                stats["frames_without_faces"] += 1
                out.write(frame)
                continue
            
            # Face detected ‚Üí Enhance with GFPGAN
            stats["frames_with_faces"] += 1
            
            try:
                aligned_face, mat = get_cropped_head_256(frame, kpss[0], size=256, scale=1.0)
                frame_buffer.append((frame, aligned_face, mat))
                
                if len(frame_buffer) >= batch_size:
                    enhancement_start = time.time()
                    try:
                        process_batch(frame_buffer, enhancer, face_mask, out, frame_width, frame_height)
                        enhancement_times.append(time.time() - enhancement_start)
                        stats["faces_enhanced"] += len(frame_buffer)
                    except Exception as e:
                        logger.error(f"‚ùå Batch processing failed: {e}")
                        # Fallback: process frames individually without enhancement
                        for frame, _, _ in frame_buffer:
                            out.write(frame)
                        stats["frames_without_faces"] += len(frame_buffer)
                    finally:
                        frame_buffer = []
                    
                    # Log performance every 10 batches
                    if len(enhancement_times) % 10 == 0:
                        avg_detection = np.mean(detection_times[-40:]) if detection_times else 0
                        avg_enhancement = np.mean(enhancement_times[-10:]) if enhancement_times else 0
                        logger.info(f"üîÑ Batch {len(enhancement_times)}: Detection={avg_detection:.3f}s, Enhancement={avg_enhancement:.3f}s")
                        
            except Exception as e:
                logger.debug(f"Face processing failed for frame {frame_idx}: {e}")
                # If face processing fails, keep original frame
                out.write(frame)
                stats["frames_with_faces"] -= 1
                stats["frames_without_faces"] += 1
        
        # Log final performance stats
        if detection_times:
            logger.info(f"üìä Average face detection time: {np.mean(detection_times):.3f}s")
        if enhancement_times:
            logger.info(f"üìä Average enhancement batch time: {np.mean(enhancement_times):.3f}s")
        
        # Process remaining frames
        if frame_buffer:
            try:
                process_batch(frame_buffer, enhancer, face_mask, out, frame_width, frame_height)
                stats["faces_enhanced"] += len(frame_buffer)
            except Exception as e:
                logger.error(f"‚ùå Final batch processing failed: {e}")
                # Fallback: process frames individually without enhancement
                for frame, _, _ in frame_buffer:
                    out.write(frame)
                stats["frames_without_faces"] += len(frame_buffer)
        
        video_stream.release()
        out.release()
        
        if stats["frames_with_faces"] > 0:
            stats["enhancement_applied"] = True
            logger.info(f"‚úÖ Face enhancement applied to {stats['frames_with_faces']}/{stats['total_frames']} frames")
        else:
            logger.info(f"‚ÑπÔ∏è No faces detected in any frame. Original video unchanged.")
            stats["enhancement_applied"] = False
        
        # Extract and combine audio
        audio_path = os.path.splitext(output_path)[0] + '.aac'
        
        subprocess.run([
            'ffmpeg', '-y', '-i', input_video_path, 
            '-vn', '-acodec', 'aac', '-b:a', '192k', audio_path
        ], check=True, capture_output=True)
        
        subprocess.run([
            'ffmpeg', '-y', '-i', temp_video_path, '-i', audio_path, 
            '-c:v', 'libx264', '-crf', '23', '-preset', 'medium', 
            '-c:a', 'aac', '-b:a', '192k', '-movflags', '+faststart', output_path
        ], check=True, capture_output=True)
        
        if os.path.exists(temp_video_path):
            os.remove(temp_video_path)
        if os.path.exists(audio_path):
            os.remove(audio_path)
        
        file_size = os.path.getsize(output_path) / (1024 * 1024)
        logger.info(f"‚úÖ Face enhancement completed: {output_path} ({file_size:.1f} MB)")
        return True, stats
        
    except Exception as e:
        logger.error(f"‚ùå Face enhancement failed: {e}")
        return False, stats
    finally:
        if 'video_stream' in locals():
            video_stream.release()
        if 'out' in locals():
            out.release()
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

def handler(job):
    """Main RunPod handler for face enhancement"""
    job_id = job.get("id", "unknown")
    start_time = time.time()
    
    try:
        job_input = job.get("input", {})
        video_url = job_input.get("video_url")
        
        if not video_url:
            return {"error": "Missing video_url parameter"}
        
        # Enhancement parameters
        batch_size = job_input.get("batch_size", 4)
        detection_threshold = job_input.get("detection_threshold", 0.3)
        
        logger.info(f"üöÄ Job {job_id}: Face Enhancement Service")
        logger.info(f"üì∫ Video: {video_url}")
        logger.info(f"‚öôÔ∏è Parameters: batch_size={batch_size}, detection_threshold={detection_threshold}")
        
        with tempfile.TemporaryDirectory() as temp_dir:
            input_video_path = os.path.join(temp_dir, "input_video.mp4")
            current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_video_path = os.path.join(temp_dir, f"enhanced_{current_time}.mp4")
            
            # Step 1: Download input video
            logger.info("üì• Step 1/3: Downloading input video...")
            if not download_file(video_url, input_video_path):
                return {"error": "Failed to download video"}
            
            # Step 2: Apply face enhancement
            logger.info("‚ú® Step 2/3: Applying face enhancement...")
            enhancement_success, face_stats = enhance_video_with_gfpgan(input_video_path, output_video_path)
            
            if not enhancement_success:
                return {"error": "Face enhancement failed"}
            
            if not os.path.exists(output_video_path):
                return {"error": "Enhanced video not generated"}
            
            # Step 3: Upload result
            logger.info("üì§ Step 3/3: Uploading enhanced video...")
            output_filename = f"enhanced_faces_{job_id}_{uuid.uuid4().hex[:8]}.mp4"
            output_url = upload_to_minio(output_video_path, output_filename)
            
            processing_time = time.time() - start_time
            
            # Prepare response
            response = {
                "output_video_url": output_url,
                "processing_time_seconds": round(processing_time, 2),
                "enhancement_stats": {
                    "total_frames": face_stats["total_frames"],
                    "frames_enhanced": face_stats["frames_with_faces"],
                    "enhancement_rate": round(face_stats["frames_with_faces"] / face_stats["total_frames"] * 100, 1) if face_stats["total_frames"] > 0 else 0,
                    "enhancement_applied": face_stats["enhancement_applied"]
                },
                "status": "completed"
            }
            
            return response
            
    except Exception as e:
        logger.error(f"‚ùå Handler error: {e}")
        return {
            "error": str(e),
            "status": "failed",
            "processing_time_seconds": round(time.time() - start_time, 2)
        }
    finally:
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

if __name__ == "__main__":
    logger.info("üöÄ Starting Face Enhancement Serverless Worker...")
    logger.info(f"üóÑÔ∏è Storage: {MINIO_ENDPOINT}/{MINIO_BUCKET}")
    logger.info(f"‚ú® Service: Face Enhancement with GFPGAN")
    
    # Verify environment
    try:
        logger.info(f"üêç Python: {sys.version}")
        logger.info(f"üî• PyTorch: {torch.__version__}")
        logger.info(f"‚ö° CUDA Available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            logger.info(f"üéÆ GPU: {torch.cuda.get_device_name()}")
            logger.info(f"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Environment check failed: {e}")
    
    # Verify model files exist
    all_models_exist = True
    for model_name, model_path in MODEL_PATHS.items():
        if os.path.exists(model_path):
            logger.info(f"‚úÖ {model_name} model verified: {model_path}")
        else:
            logger.error(f"‚ùå {model_name} model missing: {model_path}")
            all_models_exist = False
    
    if not all_models_exist:
        logger.error("‚ùå Some model files are missing!")
        sys.exit(1)
    
    # Initialize models
    try:
        initialize_models()
        logger.info("‚úÖ All models initialized successfully")
    except Exception as e:
        logger.error(f"‚ùå Model initialization failed: {e}")
        sys.exit(1)
    
    # Start RunPod serverless worker
    logger.info("‚ú® Ready to process face enhancement requests...")
    runpod.serverless.start({"handler": handler})
